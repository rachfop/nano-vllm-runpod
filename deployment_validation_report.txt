============================================================
NANO-VLLM DEPLOYMENT VALIDATION REPORT
============================================================

PLATFORM COMPATIBILITY:
  System: Darwin
  Machine: arm64
  CUDA Available: False
  Device Check: pass
    Device: mps
    Dtype: torch.float32
  Memory Check: pass
  Dependencies: pass
    flash_attention: not_available
    triton: not_available
    transformers: available

MODEL VALIDATION:
  Qwen/Qwen3-8B: pass
  meta-llama/Llama-2-7b-hf: fail
    Error: Failed to check model compatibility: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Llama-2-7b-hf.
401 Client Error. (Request ID: Root=1-69179505-09b35cf134778620692d21ad;1d368e07-0110-41fa-b865-4e086a87c0ea)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.
Access to model meta-llama/Llama-2-7b-hf is restricted. You must have access to it and be authenticated to access it. Please log in.
  mistralai/Mistral-7B-v0.1: pass

OVERALL STATUS:
  Result: FAIL
  Tests Passed: 5
  Tests Failed: 1
  Tests Skipped: 0